{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-08-01: Exploring Sparsity Estimation Algorithms\n",
    "\n",
    "*Last Updated*: 2020-08-03\n",
    "\n",
    "### Authors\n",
    "* Kevin Chu (kevin@velexi.com)\n",
    "\n",
    "### Overview\n",
    "In this Jupyter notebook, we explore algorithms for estimating dataset sparsity based on the probability that a sample of $k$ vectors from a dataset is linearly dependent.\n",
    "\n",
    "### Definitions\n",
    "\n",
    "* Let $\\Omega$ be a union of $M$ linear subspaces $\\Omega_i \\subsetneq \\mathbb{R}^n$ with $\\dim \\Omega_i \\le s$: $\\Omega = \\bigcup_i^M \\Omega_i$.\n",
    "\n",
    "* Let $W$ be a dataset drawn from $\\Omega$.\n",
    "\n",
    "### Key Results\n",
    "* Sampling of random sets of vectors from the dataset $W$ should be done _without replacement_. Since a set of vectors is linearly dependent if the set contains the same vector more than one time, sampling with replacement can lead to non-zero estimates for the probability that a sample of $k$ vectors is linearly dependent even if $k < \\min( \\dim \\Omega_i )$.\n",
    "\n",
    "### User parameters\n",
    "\n",
    "* `TODO`: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports\n",
    "\n",
    "# Standard library\n",
    "import math\n",
    "import time\n",
    "\n",
    "# External packages\n",
    "import numba\n",
    "import numpy as np\n",
    "from numpy.linalg import qr\n",
    "import seaborn as sns\n",
    "import tqdm.notebook\n",
    "\n",
    "# Local packages\n",
    "from datasets.sparse import generate_sparse_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User parameters\n",
    "\n",
    "# Generative model parameters\n",
    "concept_space_dim = 5\n",
    "sparsity = 2\n",
    "value_range = [0.5, 1.5]\n",
    "\n",
    "# Dataset parameters\n",
    "dataset_size = 20000\n",
    "\n",
    "# Algorithm parameters\n",
    "max_k = concept_space_dim\n",
    "max_k = 6\n",
    "sample_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Dependence of Sets of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define vectors_are_dependent() function\n",
    "\n",
    "def vectors_are_dependent(vectors, tol=1e-12):\n",
    "    \"\"\"\n",
    "    Determine whether a collection of vectors is linearly dependent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors: numpy.ndarray\n",
    "        set of vectors to determine linear dependence of. Note: it does not matter whether\n",
    "        vectors are stored as rows or columns.\n",
    "        \n",
    "    Return value\n",
    "    ------------\n",
    "    dependent: bool\n",
    "        True if vectors are linearly dependent; False otherwise\n",
    "    \n",
    "    min_abs_diag_R: float\n",
    "        diagonal element of R with minimum absolute value\n",
    "    \"\"\"\n",
    "    #  Handle edge case: 'vectors' contains a single vector\n",
    "    if len(vectors.shape) == 1 or min(vectors.shape) == 1:\n",
    "        min_abs_diag_R = np.abs(vectors).min()\n",
    "        dependent = min_abs_diag_R < tol\n",
    "        return dependent, min_abs_diag_R\n",
    "    \n",
    "    # Use the QR decomposition to transform the matrix 'vectors' into \n",
    "    # an upper-triangular matrix\n",
    "    if vectors.shape[0] < vectors.shape[1]:\n",
    "        R = qr(vectors.T, mode='r')\n",
    "    else:\n",
    "        R = qr(vectors, mode='r')\n",
    "\n",
    "    # Compute diagonal element with the smallest absolute value\n",
    "    if len(R.shape) == 1 or min(R.shape) == 1:\n",
    "        # Case: R is a matrix with a single row or column\n",
    "        min_abs_diag_R = abs(r[0])\n",
    "    else:\n",
    "        min_abs_diag_R = min(abs(np.diag(R)))\n",
    "\n",
    "    # Determine if vectors are linearly dependent by comparing min_abs_diag_r to 0\n",
    "    dependent = min_abs_diag_R < tol\n",
    "\n",
    "    return dependent, min_abs_diag_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vectors_are_dependent()' tests: PASSED\n"
     ]
    }
   ],
   "source": [
    "# --- Test vectors_are_dependent()\n",
    "\n",
    "# ------ Exercise functionality and check results\n",
    "\n",
    "# Dependent row vectors\n",
    "vectors = np.array([[1,1,0],[2,2,0],[3,3,0]])\n",
    "vectors = np.array([[1,1,0],[2,2,0]])\n",
    "dependent, _ = vectors_are_dependent(vectors)\n",
    "assert dependent\n",
    "\n",
    "# Dependent column vectors\n",
    "vectors = np.array([[1,2],[1,2],[0,0]])\n",
    "dependent, _ = vectors_are_dependent(vectors)\n",
    "assert dependent\n",
    "\n",
    "# Independent column vectors\n",
    "vectors = np.array([[1,1],[1,2],[0,0]])\n",
    "dependent, _ = vectors_are_dependent(vectors)\n",
    "assert not dependent\n",
    "\n",
    "# Independent row vectors\n",
    "vectors = np.array([[1,1,0],[1,2,0]])\n",
    "dependent, _ = vectors_are_dependent(vectors)\n",
    "assert not dependent\n",
    "\n",
    "# Print test results\n",
    "print(\"'vectors_are_dependent()' tests: PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define compute_P_vectors_are_dependent() function\n",
    "\n",
    "# @numba.jit(nopython=True, nogil=True)\n",
    "def compute_P_vectors_are_dependent(num_subspaces, sparsity, r):\n",
    "    \"\"\"\n",
    "    Compute probability that a sample of 'r' vectors drawn with replacement from\n",
    "    'num_subspaces' subspaces with the specified sparsity is linearly dependent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_subspaces: int\n",
    "        number of subspaces\n",
    "\n",
    "    sparsity: int\n",
    "        sparsity of subspaces\n",
    "\n",
    "    r: int\n",
    "        number of vectors to sample\n",
    "\n",
    "    Return value\n",
    "    ------------\n",
    "    probability: float\n",
    "        probability that a sample of 'r' vectors drawn with replacement from\n",
    "        'num_subspaces' subspaces with the specified sparsity is linearly dependent.\n",
    "    \"\"\"\n",
    "    # --- Check parameters\n",
    "    \n",
    "    if num_subspaces < 1:\n",
    "        raise ValueError(\"'num_subspaces' must be positive\")\n",
    "    if sparsity < 1:\n",
    "        raise ValueError(\"'sparsity' must be positive\")\n",
    "    if r < 1:\n",
    "        raise ValueError(\"'r' must be positive\")\n",
    "        \n",
    "    # --- Handle edge cases\n",
    "\n",
    "    if r < sparsity + 1:\n",
    "        return 0\n",
    "\n",
    "    # --- Compute probability\n",
    "\n",
    "    p_one_object = 0\n",
    "    for i in range(p, m+1):\n",
    "        p_one_object += math.comb(m, i) * (1/n)**i * (1 - 1/n)**(m-i)\n",
    "    probability = n * p_one_object\n",
    "\n",
    "    return probability\n",
    "\n",
    "# --- Test compute_P()\n",
    "\n",
    "# ------ Test Case #1\n",
    "\n",
    "# Preparations\n",
    "n_test = 5\n",
    "m_test = 3\n",
    "p_test = 1\n",
    "\n",
    "# Exercise functionality\n",
    "t_start = time.time()\n",
    "probability_test = compute_P(n_test, m_test, p_test)\n",
    "t_end = time.time()\n",
    "time_compute_P_first_call = t_end - t_start\n",
    "\n",
    "# Check results\n",
    "print(probability_test)\n",
    "\n",
    "# Verify computational performance boost from Numba\n",
    "t_start = time.time()\n",
    "probability_test = compute_P(n_test, m_test, p_test)\n",
    "t_end = time.time()\n",
    "time_compute_P_second_call = t_end - t_start\n",
    "\n",
    "# ------ Test Case #1\n",
    "\n",
    "# Preparations\n",
    "n_test = 10\n",
    "m_test = 4\n",
    "p_test = 3\n",
    "\n",
    "# Exercise functionality\n",
    "t_start = time.time()\n",
    "probability_test = compute_P(n_test, m_test, p_test)\n",
    "t_end = time.time()\n",
    "\n",
    "# Check results\n",
    "print(probability_test)\n",
    "\n",
    "# ------ Print results\n",
    "\n",
    "# TODO\n",
    "# print(\"'count_p_samples()' tests: PASSED\")\n",
    "print(\"Runtime 'compute_P()' (with compilation): {:.3g}s\"\n",
    "      .format(time_compute_P_first_call))\n",
    "\n",
    "print(\"Runtime 'compute_P()' (after compilation): {:.3g}s\"\n",
    "      .format(time_compute_P_second_call))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing number of arrangements with at least one object selected at least $p$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions\n",
    "\n",
    "* Let $A_{n, m, p}$ denote the number of $m$-tuples where\n",
    "\n",
    "    * each element of the tuple is drawn from a pool of $n$ classes and\n",
    "\n",
    "    * at least one class is represented at least $p$ times in the $m$-tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define count_p_samples()\n",
    "\n",
    "# @numba.jit(nopython=True, nogil=True)\n",
    "def compute_A_direct_count(n, m, p):\n",
    "    \"\"\"\n",
    "    Count number of samples of size 'm' drawn with replacement from 'n' objects with at\n",
    "    least one object represented at least 'p' times.\n",
    "    \n",
    "    This function computes A by explicitly counting them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        number of objects\n",
    "\n",
    "    m: int\n",
    "        number of samples to draw\n",
    "\n",
    "    p: int\n",
    "        target number of times at least one object is represented in the sample\n",
    "\n",
    "    Return value\n",
    "    ------------\n",
    "    num_p_samples: int\n",
    "        number of samples of size 'm' that satisfies the property that at least one object\n",
    "        is represented at least 'p' times\n",
    "    \"\"\"\n",
    "    # --- Check parameters\n",
    "    \n",
    "    if n < 1:\n",
    "        raise ValueError(\"'n' must be positive\")\n",
    "\n",
    "    if m < 1:\n",
    "        raise ValueError(\"'m' must be positive\")\n",
    "\n",
    "    if p < 1:\n",
    "        raise ValueError(\"'p' must be positive\")\n",
    "\n",
    "    # --- Preparations\n",
    "\n",
    "    # Initialize count\n",
    "    count = 0\n",
    "\n",
    "    # --- Count number of \n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, min(i+1, m+1)):\n",
    "            for k in range(1, min(j+1, p+1)):\n",
    "                print(i, j, k)\n",
    "                if k == j:\n",
    "                    sub_problem_solutions[(i, j, k)] = i\n",
    "                elif k > j:\n",
    "                    sub_problem_solutions[(i, j, k)] = 0\n",
    "                else:\n",
    "                    num_k_samples = 0\n",
    "                    for t in range(0, k):\n",
    "                        if i-1 >= j-t and j-t >= k:\n",
    "                            num_k_samples += \\\n",
    "                                math.comb(j, t) * sub_problem_solutions[(i-1, j-t, k)]\n",
    "                    for t in range(k, j+1):\n",
    "                        num_k_samples += math.comb(j, t) * (i-1)**(j-t)\n",
    "                    \n",
    "\n",
    "                    sub_problem_solutions[(i, j, k)] = num_k_samples\n",
    "                    \n",
    "    num_p_samples = sub_problem_solutions[n, m, p]\n",
    "#    print(len(sub_problem_solutions))\n",
    "#    print(sub_problem_solutions)\n",
    "\n",
    "    return num_p_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analytical Formulas\n",
    "\n",
    "##### Formula based on recursive formula\n",
    "\n",
    "* $A_{n, m, p}$ satisfies the recurrence relation:\n",
    "\n",
    "    $$\n",
    "    A_{n, m, p} = \\sum_{i = 0}^{p-1} {m \\choose i} A_{n-1, m-i, p}\n",
    "                + \\sum_{i = p}^m {m \\choose i} (n-1)^{m-i}\n",
    "    $$\n",
    "\n",
    "* __TODO__. Need to fix these formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define count_p_samples()\n",
    "\n",
    "# @numba.jit(nopython=True, nogil=True)\n",
    "def compute_A(n, m, p):\n",
    "    \"\"\"\n",
    "    Count number of samples of size 'm' drawn with replacement from 'n' objects with at\n",
    "    least one object represented at least 'p' times.\n",
    "    \n",
    "    We use dynamic programming to solve this problem.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        number of objects\n",
    "\n",
    "    m: int\n",
    "        number of samples to draw\n",
    "\n",
    "    p: int\n",
    "        target number of times at least one object is represented in the sample\n",
    "\n",
    "    Return value\n",
    "    ------------\n",
    "    num_p_samples: int\n",
    "        number of samples of size 'm' that satisfies the property that at least one object\n",
    "        is represented at least 'p' times\n",
    "    \"\"\"\n",
    "    # --- Check parameters\n",
    "    \n",
    "    if n < 1:\n",
    "        raise ValueError(\"'n' must be positive\")\n",
    "        \n",
    "    # --- Handle edge cases\n",
    "\n",
    "    if n < m:\n",
    "        return 0\n",
    "    elif m < p:\n",
    "        return 0\n",
    "    elif m == p:\n",
    "        return n\n",
    "\n",
    "    # --- Preparations\n",
    "\n",
    "    # Initialize dynamic programming \"table\"\n",
    "    sub_problem_solutions = {}\n",
    "\n",
    "    # Initialize num_p_samples\n",
    "    num_p_samples = 0\n",
    "\n",
    "    # --- Compute num_p_samples using dynamic programming\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, min(i+1, m+1)):\n",
    "            for k in range(1, min(j+1, p+1)):\n",
    "                print(i, j, k)\n",
    "                if k == j:\n",
    "                    sub_problem_solutions[(i, j, k)] = i\n",
    "                elif k > j:\n",
    "                    sub_problem_solutions[(i, j, k)] = 0\n",
    "                else:\n",
    "                    num_k_samples = 0\n",
    "                    for t in range(0, k):\n",
    "                        if i-1 >= j-t and j-t >= k:\n",
    "                            num_k_samples += \\\n",
    "                                math.comb(j, t) * sub_problem_solutions[(i-1, j-t, k)]\n",
    "                    for t in range(k, j+1):\n",
    "                        num_k_samples += math.comb(j, t) * (i-1)**(j-t)\n",
    "                    \n",
    "\n",
    "#                     sub_problem_solutions[(i, j, k)] = num_k_samples\n",
    "                    \n",
    "    num_p_samples = sub_problem_solutions[n, m, p]\n",
    "#    print(len(sub_problem_solutions))\n",
    "#    print(sub_problem_solutions)\n",
    "\n",
    "    return num_p_samples\n",
    "\n",
    "# # --- Test count_p_samples()\n",
    "\n",
    "# # ------ Test Case #1\n",
    "\n",
    "# # Preparations\n",
    "# n_test = 5\n",
    "# m_test = 3\n",
    "# p_test = 1\n",
    "\n",
    "# # Exercise functionality\n",
    "# t_start = time.time()\n",
    "# num_p_samples_test = count_p_samples(n_test, m_test, p_test)\n",
    "# t_end = time.time()\n",
    "# time_count_p_samples_first_call = t_end - t_start\n",
    "\n",
    "# # Check results\n",
    "# print(num_p_samples_test)\n",
    "\n",
    "# # Verify computational performance boost from Numba\n",
    "# t_start = time.time()\n",
    "# num_p_samples_test = count_p_samples(n_test, m_test, p_test)\n",
    "# t_end = time.time()\n",
    "# time_count_p_samples_second_call = t_end - t_start\n",
    "\n",
    "# # ------ Test Case #2\n",
    "\n",
    "# # Preparations\n",
    "# n_test = 10\n",
    "# m_test = 1\n",
    "# p_test = 2\n",
    "\n",
    "# # Exercise functionality\n",
    "# t_start = time.time()\n",
    "# num_p_samples_test = count_p_samples(n_test, m_test, p_test)\n",
    "# t_end = time.time()\n",
    "# time_count_p_samples = t_end - t_start\n",
    "\n",
    "# # Check results\n",
    "# assert num_p_samples_test == 0\n",
    "\n",
    "# # ------ Test Case #3\n",
    "\n",
    "# # Preparations\n",
    "# n_test = 10\n",
    "# m_test = 12\n",
    "# p_test = 2\n",
    "\n",
    "# # Exercise functionality\n",
    "# t_start = time.time()\n",
    "# num_p_samples_test = count_p_samples(n_test, m_test, p_test)\n",
    "# t_end = time.time()\n",
    "# time_count_p_samples = t_end - t_start\n",
    "\n",
    "# # Check results\n",
    "# assert num_p_samples_test == 0\n",
    "\n",
    "# # ------ Test Case #4\n",
    "\n",
    "# # Preparations\n",
    "# n_test = 10\n",
    "# m_test = 4\n",
    "# p_test = 4\n",
    "\n",
    "# # Exercise functionality\n",
    "# t_start = time.time()\n",
    "# num_p_samples_test = count_p_samples(n_test, m_test, p_test)\n",
    "# t_end = time.time()\n",
    "# time_count_p_samples = t_end - t_start\n",
    "\n",
    "# # Check results\n",
    "# assert num_p_samples_test == n_test\n",
    "\n",
    "# # ------ Test Case #5\n",
    "\n",
    "# # Preparations\n",
    "# n_test = 10\n",
    "# m_test = 6\n",
    "# p_test = 2\n",
    "\n",
    "# # Exercise functionality\n",
    "# t_start = time.time()\n",
    "# num_p_samples_test = count_p_samples(n_test, m_test, p_test)\n",
    "# t_end = time.time()\n",
    "# time_count_p_samples = t_end - t_start\n",
    "\n",
    "# # ------ Test Case #6\n",
    "\n",
    "# # Preparations\n",
    "# n_test = 10\n",
    "# m_test = 3\n",
    "# p_test = 3\n",
    "\n",
    "# # Exercise functionality\n",
    "# t_start = time.time()\n",
    "# num_p_samples_test = count_p_samples(n_test, m_test, p_test)\n",
    "# t_end = time.time()\n",
    "# time_count_p_samples = t_end - t_start\n",
    "\n",
    "# # Check results\n",
    "# print(num_p_samples_test)\n",
    "\n",
    "# # ------ Print results\n",
    "\n",
    "# # TODO\n",
    "# # print(\"'count_p_samples()' tests: PASSED\")\n",
    "# print(\"Runtime 'count_p_samples()' (with compilation): {:.3g}s\"\n",
    "#       .format(time_count_p_samples_first_call))\n",
    "\n",
    "# print(\"Runtime 'count_p_samples()' (after compilation): {:.3g}s\"\n",
    "#       .format(time_count_p_samples_second_call))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration\n",
    "\n",
    "# Seaborn configuration\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime 'generate_sparse_vectors()': 0.403s\n"
     ]
    }
   ],
   "source": [
    "# Compute number of subspaces\n",
    "num_subspaces = math.comb(concept_space_dim, sparsity)\n",
    "\n",
    "# Generate dataset\n",
    "t_start = time.time()\n",
    "dataset = generate_sparse_vectors(concept_space_dim, sparsity, value_range, dataset_size)\n",
    "t_end = time.time()\n",
    "time_generate_sparse_vectors = t_end - t_start\n",
    "\n",
    "# Print timing data\n",
    "print(\"Runtime 'generate_sparse_vectors()': {:.3g}s\".format(time_generate_sparse_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Significant Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept space dimension = 5\n",
      "sparsity = 2\n",
      "num_subspaces = 10\n",
      "dataset size = 20000\n",
      "sample size = 10000\n"
     ]
    }
   ],
   "source": [
    "# --- Display parameters that affect algorithm performance\n",
    "\n",
    "print(\"concept space dimension = {}\".format(concept_space_dim))\n",
    "print(\"sparsity = {}\".format(sparsity))\n",
    "print(\"num_subspaces = {}\".format(num_subspaces))\n",
    "\n",
    "print(\"dataset size = {}\".format(dataset_size))\n",
    "print(\"sample size = {}\".format(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Formula based on recursive formula\n",
    "\n",
    "# print(\"Number of linearly dependent samples\")\n",
    "# for k in range(1, max_k+1):\n",
    "#     N = count_p_samples(num_subspaces, k, sparsity+1)\n",
    "#     print('    N({} sample vectors) = {}'.format(k, N))\n",
    "#     print('    P(outer product of {} vectors = 0) = {}'.format(k, N/num_subspaces**k))\n",
    "    \n",
    "\n",
    "# for k in range(1, max_k+1):\n",
    "#     count = 0\n",
    "#     for s in range(1, k+1):\n",
    "#         print('AA', num_subspaces, k, s, count_p_samples(num_subspaces, k, s))\n",
    "#         count += count_p_samples(num_subspaces, k, s)\n",
    "\n",
    "#     print('k = {}'.format(k))\n",
    "#     print('total number of arrangements({}) = {}'.format(k, count))\n",
    "#     print('num subspaces**k = {}'.format(num_subspaces**k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula based on counting arrangements of boundaries, grouped vectors, and individual vectors\n",
    "\n",
    "* TODO: clean up definitions\n",
    "\n",
    "* The space between the $i$-th and $(i+1)$-th boundaries represents the vectors contained in the $i$-th subspace. The position of the first and last boundaries are fixed.\n",
    "* A group of $s+1$ vectors that are linearly dependent (i.e., all reside in a single subspace) is treated as a single object.\n",
    "* The remaining $k - (s+1)$ vectors are treated as individual objects.\n",
    "\n",
    "##### Open Questions\n",
    "* Do we need a factor of $(s+1)!$ is to account for the fact that there are that many different arrangements of the vectors in the linearly dependent set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of linearly dependent sample (via arrangement counting)\n",
      "    N(1 sample vectors) = 0\n",
      "    P(outer product of 1 vectors = 0) = 0.0\n",
      "    N(2 sample vectors) = 0\n",
      "    P(outer product of 2 vectors = 0) = 0.0\n",
      "    N(3 sample vectors) = 10\n",
      "    P(outer product of 3 vectors = 0) = 0.01\n",
      "    N(4 sample vectors) = 660\n",
      "    P(outer product of 4 vectors = 0) = 0.066\n",
      "    N(5 sample vectors) = 7920\n",
      "    P(outer product of 5 vectors = 0) = 0.0792\n",
      "    N(6 sample vectors) = 102960\n",
      "    P(outer product of 6 vectors = 0) = 0.10296\n",
      "9 1 9 0\n",
      "9\n",
      "k = 1\n",
      "test_N(1) = 9\n",
      "num movable boundaries + num vectors = 9\n",
      "(num movable boundaries + num vectors) choose (num movable boundaries) = 9\n",
      "10 1 10 1\n",
      "90\n",
      "10 2 9 0\n",
      "99\n",
      "k = 2\n",
      "test_N(2) = 99\n",
      "num movable boundaries + num vectors = 10\n",
      "(num movable boundaries + num vectors) choose (num movable boundaries) = 45\n",
      "11 1 11 2\n",
      "495\n",
      "11 2 10 1\n",
      "585\n",
      "11 3 9 0\n",
      "594\n",
      "k = 3\n",
      "test_N(3) = 594\n",
      "num movable boundaries + num vectors = 11\n",
      "(num movable boundaries + num vectors) choose (num movable boundaries) = 165\n",
      "12 1 12 3\n",
      "1980\n",
      "12 2 11 2\n",
      "2475\n",
      "12 3 10 1\n",
      "2565\n",
      "12 4 9 0\n",
      "2574\n",
      "k = 4\n",
      "test_N(4) = 2574\n",
      "num movable boundaries + num vectors = 12\n",
      "(num movable boundaries + num vectors) choose (num movable boundaries) = 495\n",
      "13 1 13 4\n",
      "6435\n",
      "13 2 12 3\n",
      "8415\n",
      "13 3 11 2\n",
      "8910\n",
      "13 4 10 1\n",
      "9000\n",
      "13 5 9 0\n",
      "9009\n",
      "k = 5\n",
      "test_N(5) = 9009\n",
      "num movable boundaries + num vectors = 13\n",
      "(num movable boundaries + num vectors) choose (num movable boundaries) = 1287\n",
      "14 1 14 5\n",
      "18018\n",
      "14 2 13 4\n",
      "24453\n",
      "14 3 12 3\n",
      "26433\n",
      "14 4 11 2\n",
      "26928\n",
      "14 5 10 1\n",
      "27018\n",
      "14 6 9 0\n",
      "27027\n",
      "k = 6\n",
      "test_N(6) = 27027\n",
      "num movable boundaries + num vectors = 14\n",
      "(num movable boundaries + num vectors) choose (num movable boundaries) = 3003\n"
     ]
    }
   ],
   "source": [
    "# --- Formula based on arrangement counting\n",
    "\n",
    "print(\"Number of linearly dependent sample (via arrangement counting)\")\n",
    "for k in range(1, max_k+1):\n",
    "    num_individual_vectors = k - (sparsity + 1)\n",
    "    num_objs = (num_subspaces - 1) + 1 + num_individual_vectors\n",
    "\n",
    "    if num_individual_vectors == 0:\n",
    "        N = math.comb(num_objs, 1)\n",
    "    elif num_individual_vectors > 0:\n",
    "        N = math.comb(num_objs, 1) * math.comb(num_objs-1, num_individual_vectors) \\\n",
    "            * math.factorial(num_individual_vectors) * math.factorial(sparsity + 1)\n",
    "    else:\n",
    "        N = 0\n",
    "\n",
    "    print('    N({} sample vectors) = {}'.format(k, N))\n",
    "    print('    P(outer product of {} vectors = 0) = {}'.format(k, N/num_subspaces**k))\n",
    "\n",
    "for k in range(1, max_k+1):\n",
    "    test_N = 0\n",
    "    for j in range(1, min(k+1, num_subspaces+1)):\n",
    "        num_individual_vectors = k - j\n",
    "        num_objs = (num_subspaces - 2) + 1 + num_individual_vectors\n",
    "\n",
    "        print(num_subspaces + k - 2, j, num_objs, num_individual_vectors)\n",
    "        if num_individual_vectors == 0:\n",
    "            test_N += math.comb(num_objs, 1)\n",
    "        elif num_individual_vectors > 0:\n",
    "            test_N += math.comb(num_objs, 1) * math.comb(num_objs-1, num_individual_vectors)\n",
    "#                * math.factorial(num_individual_vectors) * math.factorial(test_sparsity + 1)\n",
    "        print(test_N)\n",
    "\n",
    "    print('k = {}'.format(k))\n",
    "    print('test_N({}) = {}'.format(k, test_N))\n",
    "    print('num movable boundaries + num vectors = {}'.format(num_subspaces + k - 2))\n",
    "    print('(num movable boundaries + num vectors) choose (num movable boundaries) = {}'\n",
    "          .format(math.comb(num_subspaces + k - 2, num_subspaces - 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample vectors with replacement\n",
    "\n",
    "* _False Positives_. For a finite dataset $W$ (in contrast to the   space $\\Omega$), there\n",
    "  is a nonzero probability of drawing a sample that is linearly dependent just because the\n",
    "  same vector from $W$ is drawn more than one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Compute probabilities when samples are taken with replacement\n",
    "\n",
    "# # Initialize probabilities that outer products of $k$ vectors is zero\n",
    "# p_dependent_with_replacement = np.zeros([max_k])\n",
    "    \n",
    "# # Loop over number of vectors to sample from dataset\n",
    "\n",
    "# with tqdm.notebook.trange(2, max_k+1) as k_range:\n",
    "#     for k in k_range:\n",
    "#         k_range.set_description(\"Processing k={} (with replacement)\".format(k))\n",
    "        \n",
    "#         # Initialize count for linearly dependent samples\n",
    "#         count_dependent = 0\n",
    "    \n",
    "#         # Generate samples and check linear dependence\n",
    "#         for _ in tqdm.notebook.tqdm(range(sample_size), unit='samples',\n",
    "#                                     desc='Sampling {} vectors'.format(k), leave=False):\n",
    "#             indices = np.random.choice(dataset_size, k, replace=True)\n",
    "#             vectors = dataset[indices, :]\n",
    "#             dependent, min_abs_diag_R = vectors_are_dependent(vectors)\n",
    "#             if dependent:\n",
    "#                 count_dependent += 1\n",
    "            \n",
    "#             p_dependent_with_replacement[k-1] = count_dependent / sample_size\n",
    "\n",
    "# # Display results\n",
    "# print(\"Probabilities when samples are taken with replacement\")\n",
    "# for k in range(max_k):\n",
    "#     print('    P(outer product of {} vectors = 0) = {:.5g}'\n",
    "#           .format(k+1, p_dependent_with_replacement[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample vectors without replacement\n",
    "\n",
    "* _Poor Computational Performance_. The computational performance of sampling without\n",
    "  replacement is much lower than sampling with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49fb3e258be43fc84a1866e9c5c2cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sampling 2 vectors', max=10000.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sampling 3 vectors', max=10000.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sampling 4 vectors', max=10000.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sampling 5 vectors', max=10000.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sampling 6 vectors', max=10000.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities when samples are taken without replacement\n",
      "    P(outer product of 1 vectors = 0) = 0, Expected = 0\n",
      "    P(outer product of 2 vectors = 0) = 0, Expected = 0\n",
      "    P(outer product of 3 vectors = 0) = 0.0088, Expected = 0.01\n",
      "    P(outer product of 4 vectors = 0) = 0.0917, Expected = 0.037\n",
      "    P(outer product of 5 vectors = 0) = 0.4154, Expected = 0.0856\n",
      "    P(outer product of 6 vectors = 0) = 0.2443, Expected = 0.1585\n"
     ]
    }
   ],
   "source": [
    "# --- Compute probabilities when samples are taken without replacement\n",
    "\n",
    "# Initialize probabilities that outer products of $k$ vectors is zero\n",
    "p_dependent_without_replacement = np.zeros([max_k])\n",
    "    \n",
    "# Loop over number of vectors to sample from dataset\n",
    "\n",
    "with tqdm.notebook.trange(2, max_k+1) as k_range:\n",
    "    for k in k_range:\n",
    "        k_range.set_description(\"Processing k={} (without replacement)\".format(k))\n",
    "        \n",
    "        # Initialize count for linearly dependent samples\n",
    "        count_dependent = 0\n",
    "    \n",
    "        # Generate samples and check linear dependence\n",
    "        for _ in tqdm.notebook.tqdm(range(sample_size), unit='samples',\n",
    "                                    desc='Sampling {} vectors'.format(k), leave=False):\n",
    "            indices = np.random.choice(dataset_size, k, replace=False)\n",
    "            vectors = dataset[indices, :]\n",
    "            dependent, min_abs_diag_R = vectors_are_dependent(vectors)\n",
    "            if dependent:\n",
    "                count_dependent += 1\n",
    "            \n",
    "            p_dependent_without_replacement[k-1] = count_dependent / sample_size\n",
    "\n",
    "# Display results\n",
    "print(\"Probabilities when samples are taken without replacement\")\n",
    "for k in range(max_k):\n",
    "    expected_probability = compute_P(num_subspaces, k+1, sparsity+1)\n",
    "    print('    P(outer product of {} vectors = 0) = {:.5g}, Expected = {:0.5g}'\n",
    "          .format(k+1, p_dependent_without_replacement[k], expected_probability))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
